# ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§ Rehberi

## ğŸ“‹ Gereksinimler

- Windows 10/11 (macOS/Linux da desteklenir)
- Python 3.11+ 
- Node.js 16+
- En az 4GB RAM
- Ä°nternet baÄŸlantÄ±sÄ± (model indirme iÃ§in)

## âš¡ 3 Dakikada Ã‡alÄ±ÅŸtÄ±rÄ±n

### 1ï¸âƒ£ Ollama Kurulumu (2 dakika)

```powershell
# PowerShell'i yÃ¶netici olarak aÃ§Ä±n
winget install ollama

# Model indirin
ollama pull llama3.2

# Servisi baÅŸlatÄ±n
ollama serve
```

### 2ï¸âƒ£ Projeyi BaÅŸlatÄ±n (1 dakika)

```bash
# Proje dizinine gidin
cd C:\path\to\Loggy

# Tek komutla baÅŸlatÄ±n
start.bat
```

### 3ï¸âƒ£ Test Edin

```bash
# Backend test
curl http://localhost:8000/health

# LLM test
python test_llm.py

# Web arayÃ¼zÃ¼
# http://localhost:3000
```

## ğŸ”§ Sorun mu YaÅŸÄ±yorsunuz?

### Ollama BulunamÄ±yor
```powershell
$env:PATH += ";C:\Users\$env:USERNAME\AppData\Local\Programs\Ollama"
```

### Port 8000 KullanÄ±mda
```powershell
tasklist | findstr python
taskkill /PID [PID] /F
```

### Model Ä°ndirilemiyor
```bash
# VPN kullanÄ±n veya farklÄ± aÄŸ deneyin
ollama pull llama3.2
```

### Frontend HatasÄ±
```bash
cd frontend
rm -rf node_modules package-lock.json
npm install --legacy-peer-deps
```

## ğŸ¯ Ä°lk Log Analizinizi YapÄ±n

1. **http://localhost:3000** adresini aÃ§Ä±n
2. `data/sample_logs.csv` dosyasÄ±nÄ± yÃ¼kleyin
3. "Analiz Et" butonuna tÄ±klayÄ±n
4. SonuÃ§larÄ± inceleyin!

## ğŸ“ Destek

- **DokÃ¼mantasyon:** http://localhost:8000/docs
- **Health Check:** http://localhost:8000/health  
- **Test Script:** `python test_llm.py`

---

**ğŸ‰ BaÅŸarÄ±lar! ArtÄ±k AI destekli log analiziniz hazÄ±r!**
