# ğŸ§  AkÄ±llÄ± Log AsistanÄ± (AI-Powered Log Analyzer)

Bu proje, sistem yÃ¶neticilerinin manuel olarak incelemek zorunda kaldÄ±ÄŸÄ± bÃ¼yÃ¼k boyutlu log dosyalarÄ±nÄ± AI ile analiz ederek, potansiyel anomalileri otomatik olarak tespit eden bir kurum iÃ§i log analiz aracÄ±dÄ±r.

> ğŸ¯ MVP SÃ¼rÃ¼m: Anomali tespiti, log yÃ¼kleme ve gÃ¶rsel uyarÄ± sistemi iÃ§erir.  
> ğŸ¢ Kurum iÃ§i Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r. TÃ¼m bileÅŸenler Docker Ã¼zerinde local olarak Ã§alÄ±ÅŸÄ±r.

---

## ğŸš€ Ã–zellikler

- âœ… CSV / LOG dosyasÄ± yÃ¼kleme
- âœ… LLM destekli akÄ±llÄ± anomali tespiti (Llama 3.2)
- âœ… Kritik hata uyarÄ±sÄ± ve detaylÄ± aÃ§Ä±klamalar
- âœ… Web arayÃ¼zÃ¼ ile loglarÄ± inceleme ve filtreleme
- âœ… Kurum iÃ§i daÄŸÄ±tÄ±m (offline kullanÄ±m)
- ğŸ†• DoÄŸal dil iÅŸleme ile geliÅŸmiÅŸ log analizi

---

## ğŸ“ Proje YapÄ±sÄ±

log-analyzer/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI backend
â”‚ â”œâ”€â”€ model.py # ML model yÃ¼kleme ve tahmin
â”‚ â”œâ”€â”€ utils.py # Veri iÅŸleme
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ public/ # Statik dosyalar
â”‚ â”œâ”€â”€ src/ # React app (shadcn/ui ile)
â”œâ”€â”€ data/
â”‚ â””â”€â”€ example.csv # Ã–rnek log dosyasÄ±
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md

yaml
Kopyala
DÃ¼zenle

---

## ğŸ› ï¸ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

### âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§ (3 dakikada Ã§alÄ±ÅŸÄ±r!)

#### **1. Ollama Kurulumu (AI Motor)**

**Windows:**
```powershell
# PowerShell'i yÃ¶netici olarak aÃ§Ä±n
winget install ollama
# veya
# https://ollama.ai/download adresinden indirin
```

**macOS/Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### **2. AI Modelini Ä°ndirin**
```bash
# Llama 3.2 modelini indirin (2-3 dakika sÃ¼rer)
ollama pull llama3.2

# Ollama servisini baÅŸlatÄ±n
ollama serve
```

#### **3. Python Environment HazÄ±rlÄ±ÄŸÄ±**
```bash
# Python 3.11 kullanmanÄ±z Ã¶nerilir (uyumluluk iÃ§in)
conda create -n loggy-py311 python=3.11 -y
conda activate loggy-py311
```

#### **4. Projeyi Ã‡alÄ±ÅŸtÄ±rÄ±n**

**Otomatik BaÅŸlatma (Windows):**
```bash
# Proje dizinine gidin
cd C:\path\to\Loggy

# Tek komutla baÅŸlatÄ±n
start.bat
```

**Manuel BaÅŸlatma:**
```bash
# Backend'i baÅŸlatÄ±n
cd backend
pip install -r requirements.txt
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Yeni terminal'de frontend'i baÅŸlatÄ±n
cd frontend
npm install --legacy-peer-deps
npm start
```
### ğŸ” **Sistem Durumu KontrolÃ¼**

```bash
# 1. Ollama Ã§alÄ±ÅŸÄ±yor mu?
ollama --version
ollama list  # Modeller listelensin

# 2. Backend Ã§alÄ±ÅŸÄ±yor mu?
curl http://localhost:8000/health
# YanÄ±t: {"status":"healthy","database":"connected","llm":"ready","model":"llama3.2"}

# 3. Frontend Ã§alÄ±ÅŸÄ±yor mu?
# http://localhost:3000 adresini tarayÄ±cÄ±da aÃ§Ä±n
```

### ğŸŒ **EriÅŸim Adresleri**

- **Frontend:** http://localhost:3000
- **Backend API:** http://localhost:8000
- **API DokÃ¼mantasyonu:** http://localhost:8000/docs
- **Health Check:** http://localhost:8000/health

### ğŸ”§ **Sorun Giderme**

**Problem: "Ollama bulunamadÄ±"**
```bash
# PATH'e ekleyin
$env:PATH += ";C:\Users\$env:USERNAME\AppData\Local\Programs\Ollama"
```

**Problem: "Model bulunamadÄ±"**
```bash
ollama pull llama3.2  # Modeli yeniden indirin
ollama serve          # Servisi baÅŸlatÄ±n
```

**Problem: "Port 8000 kullanÄ±mda"**
```bash
# Ã‡alÄ±ÅŸan Python processlerini durdurun
tasklist | findstr python
taskkill /PID [PID_NUMBER] /F
```

**Problem: "Frontend npm hatasÄ±"**
```bash
cd frontend
rm -rf node_modules package-lock.json
npm install --legacy-peer-deps
```

### ğŸ“Š **NasÄ±l KullanÄ±lÄ±r?**

1. **Web arayÃ¼zÃ¼ne gidin:** http://localhost:3000
2. **Log dosyanÄ±zÄ± yÃ¼kleyin:** `.csv`, `.log` veya `.txt` formatÄ±nda
3. **Analizi baÅŸlatÄ±n:** "Analiz Et" butonuna tÄ±klayÄ±n
4. **SonuÃ§larÄ± inceleyin:** LLM otomatik olarak anomalileri tespit edecek

### ğŸ§ª **HÄ±zlÄ± Test**

```bash
# Test scriptini Ã§alÄ±ÅŸtÄ±rÄ±n
python test_llm.py

# Ã–rnek Ã§Ä±ktÄ±:
# âœ… Analiz baÅŸarÄ±lÄ±!
# ğŸ“Š Toplam satÄ±r: 5
# âš ï¸  Anomali sayÄ±sÄ±: 2
# ğŸš¨ Kritik sayÄ±sÄ±: 2
# ğŸ“ˆ Anomali oranÄ±: 40.00%
```

### ğŸ“ **Ã–rnek Log DosyalarÄ±**

- `data/sample_logs.csv` - Test iÃ§in hazÄ±r log dosyasÄ±
- Desteklenen formatlar: CSV, LOG, TXT
- Maksimum dosya boyutu: 50MB

ğŸ§ª Test Log Verisi
LogPai HDFS Dataset

LogPai BGL Dataset (Berkeley)

data/ klasÃ¶rÃ¼ne .csv olarak koyabilirsiniz.

ğŸ”’ GÃ¼venlik ve Gizlilik
Bu uygulama sadece kurum iÃ§i Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r

KullanÄ±cÄ± verisi dÄ±ÅŸarÄ± aktarÄ±lmaz

IP, kullanÄ±cÄ± adÄ± gibi PII alanlarÄ± maskelemeye uygundur

KullanÄ±cÄ± oturumu gerektirmez (tek kullanÄ±cÄ± iÃ§in MVP)

ğŸ§© Teknolojiler
Backend: Python, FastAPI

AI/LLM: Ollama + Llama 3.2 (yerel, Ã¼cretsiz)

Frontend: React.js, TailwindCSS, Shadcn/UI

DaÄŸÄ±tÄ±m: Docker, Docker Compose

VeritabanÄ±: SQLite (yerel, hafif)

ğŸ“¬ Ä°letiÅŸim
Bu proje, sistem gÃ¼venliÄŸi ve log analizi sÃ¼reÃ§lerini modernleÅŸtirmek amacÄ±yla geliÅŸtirilmiÅŸtir.
Her tÃ¼rlÃ¼ geri bildirim veya geliÅŸtirme Ã¶neriniz iÃ§in bizimle iletiÅŸime geÃ§ebilirsiniz.